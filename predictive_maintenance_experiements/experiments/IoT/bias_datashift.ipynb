{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT LIBRARIES\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, MinMaxScaler, normalize\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "### READ DATA\n",
    "##### Needs to be ran from the project directory\n",
    "train_measurements = pd.read_csv('../../datasets/IoT/measurements.csv')\n",
    "train_measurements = train_measurements.sort_values(by=['measurement_time'], ascending=[True])\n",
    "\n",
    "train_failures = pd.read_csv('../../datasets/IoT/failures.csv')\n",
    "train_failures = train_failures.sort_values(by=['failure_time'], ascending=[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_measurements.measurement_time = pd.to_datetime(train_measurements.measurement_time, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "train_failures.failure_time = pd.to_datetime(train_failures.failure_time)\n",
    "\n",
    "### MERGE NEXT FAILURE TO MEASUREMENTS\n",
    "train_combined = pd.merge_asof(\n",
    "    train_measurements,\n",
    "    train_failures,\n",
    "    left_on='measurement_time',\n",
    "    right_on='failure_time',\n",
    "    by='gadget_id',\n",
    "    direction='forward',\n",
    ")\n",
    "\n",
    "### TRANSFORM COLUMNS\n",
    "train_combined['time_to_fail'] = train_combined['failure_time']-train_combined['measurement_time']\n",
    "train_combined['fail_in_1h'] = np.where(train_combined['time_to_fail']<pd.Timedelta(hours=1), 1, 0)\n",
    "\n",
    "### CALCULATE RUNNING MEASURES\n",
    "train_combined = train_combined.reset_index(drop=True)\n",
    "train_combined = train_combined.sort_values(by=['gadget_id', 'measurement_time'], ascending=[True, True])\n",
    "\n",
    "train_combined['temperature_6h_std'] = train_combined.groupby('gadget_id')['temperature'].rolling(6).std(ddof=0).reset_index(drop=True)\n",
    "train_combined['pressure_6h_mean'] = train_combined.groupby('gadget_id')['pressure'].rolling(6).mean().reset_index(drop=True)\n",
    "\n",
    "train_combined.to_csv('../../datasets/IoT/train_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(978, 13)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "### SPLIT TO TRAIN AND TEST\n",
    "X = ['vibration_y', 'pressure_6h_mean', 'temperature_6h_std']\n",
    "y = 'fail_in_1h'\n",
    "cols = X + [y]\n",
    "\n",
    "df_to_split = train_combined.copy()\n",
    "df_to_split = df_to_split.dropna(subset=cols)\n",
    "df_to_split = df_to_split.reset_index(drop=True)\n",
    "df_to_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data: (685, 43)\nTest data: (293, 43)\nTest1 data: (293, 43)\n"
     ]
    }
   ],
   "source": [
    "##### Create binary bins to \n",
    "binner = KBinsDiscretizer(n_bins=10, encode='onehot-dense', strategy='kmeans')\n",
    "binner.fit(df_to_split[X])\n",
    "arr_bins= binner.transform(df_to_split[X])\n",
    "df_bins = pd.DataFrame(arr_bins)\n",
    "\n",
    "X = list(df_bins.columns)\n",
    "cols = X + [y]\n",
    "\n",
    "df_to_split = pd.concat([df_to_split, df_bins], axis=1)\n",
    "\n",
    "df_train = df_to_split.sample(frac=0.7)\n",
    "df_test = df_to_split.drop(df_train.index)\n",
    "df_test1 = df_test[df_test['gadget_id'].isin([1,2,3])].reset_index(drop=True).copy()\n",
    "df_test2 = df_test[df_test['gadget_id'].isin([4,5,6])].reset_index(drop=True).copy()\n",
    "\n",
    "print(f\"Training data: {df_train.shape}\")\n",
    "print(f\"Test data: {df_test.shape}\")\n",
    "print(f\"Test1 data: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data: (685, 43)\nDF1 data: (352, 43)\nDF2 data: (333, 43)\nDF1+2 data: 685\n"
     ]
    }
   ],
   "source": [
    "df_1 = df_train[df_train['gadget_id'].isin([1,2,3])].reset_index(drop=True).copy()\n",
    "df_2 = df_train[df_train['gadget_id'].isin([4,5,6])].reset_index(drop=True).copy()\n",
    "\n",
    "print(f\"Training data: {df_train.shape}\")\n",
    "print(f\"DF1 data: {df_1.shape}\")\n",
    "print(f\"DF2 data: {df_2.shape}\")\n",
    "print(f\"DF1+2 data: {df_2.shape[0]+df_1.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PREDICTION PARAMETERS\n",
    "w0 = 1\n",
    "w1 = 8\n",
    "pos_label = 1\n",
    "\n",
    "### LOGISTIC REGRESSION MODEL\n",
    "log_regr = LogisticRegression(class_weight={0:w0, 1:w1})\n",
    "\n",
    "### SVM\n",
    "svm = SVC(\n",
    "    class_weight={0:w0, 1:w1},\n",
    "    C=1,\n",
    "    random_state=42,\n",
    "    kernel='linear'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy 0.741\nclassification report: \n               precision    recall  f1-score   support\n\n           0       0.99      0.72      0.84       268\n           1       0.24      0.96      0.39        25\n\n    accuracy                           0.74       293\n   macro avg       0.62      0.84      0.61       293\nweighted avg       0.93      0.74      0.80       293\n\n"
     ]
    }
   ],
   "source": [
    "svm.fit(df_train[X], df_train[y])\n",
    "test1 = svm.predict(df_test[X])\n",
    "accuracy1 = accuracy_score(df_test['fail_in_1h'], test1 )\n",
    "cls1 = classification_report(df_test['fail_in_1h'], test1)\n",
    "\n",
    "print(\"accuracy\", round(accuracy1,3))\n",
    "print(\"classification report: \\n\", cls1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Full Test Set: \n\naccuracy2 0.747\nclassification report: \n               precision    recall  f1-score   support\n\n           0       0.98      0.74      0.84       268\n           1       0.24      0.88      0.37        25\n\n    accuracy                           0.75       293\n   macro avg       0.61      0.81      0.61       293\nweighted avg       0.92      0.75      0.80       293\n\nSame Samples from Test Set: \n\naccuracy2 0.772\nclassification report: \n               precision    recall  f1-score   support\n\n           0       0.99      0.75      0.85       121\n           1       0.32      0.93      0.47        15\n\n    accuracy                           0.77       136\n   macro avg       0.65      0.84      0.66       136\nweighted avg       0.92      0.77      0.81       136\n\nOther training Set (DF2): \n\naccuracy2 0.7\nclassification report: \n               precision    recall  f1-score   support\n\n           0       0.98      0.67      0.80       292\n           1       0.28      0.90      0.43        41\n\n    accuracy                           0.70       333\n   macro avg       0.63      0.79      0.61       333\nweighted avg       0.89      0.70      0.75       333\n\n"
     ]
    }
   ],
   "source": [
    "svm.fit(df_1[X], df_1[y])\n",
    "test2 = svm.predict(df_test[X])\n",
    "accuracy2 = accuracy_score(df_test['fail_in_1h'], test2 )\n",
    "cls2 = classification_report(df_test['fail_in_1h'], test2)\n",
    "print(\"Full Test Set: \\n\")\n",
    "print(\"accuracy2\", round(accuracy2,3))\n",
    "print(\"classification report: \\n\", cls2)\n",
    "\n",
    "test2 = svm.predict(df_test1[X])\n",
    "accuracy2 = accuracy_score(df_test1['fail_in_1h'], test2 )\n",
    "cls2 = classification_report(df_test1['fail_in_1h'], test2)\n",
    "print(\"Same Samples from Test Set: \\n\")\n",
    "print(\"accuracy2\", round(accuracy2,3))\n",
    "print(\"classification report: \\n\", cls2)\n",
    "\n",
    "test2 = svm.predict(df_2[X])\n",
    "accuracy2 = accuracy_score(df_2['fail_in_1h'], test2 )\n",
    "cls2 = classification_report(df_2['fail_in_1h'], test2)\n",
    "print(\"Other training Set (DF2): \\n\")\n",
    "print(\"accuracy2\", round(accuracy2,3))\n",
    "print(\"classification report: \\n\", cls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Full Test Set: \n\naccuracy3 0.741\nclassification report: \n               precision    recall  f1-score   support\n\n           0       0.99      0.72      0.84       268\n           1       0.24      0.96      0.39        25\n\n    accuracy                           0.74       293\n   macro avg       0.62      0.84      0.61       293\nweighted avg       0.93      0.74      0.80       293\n\nSame Samples from Test Set: \n\naccuracy3 0.778\nclassification report: \n               precision    recall  f1-score   support\n\n           0       1.00      0.75      0.86       316\n           1       0.32      1.00      0.48        36\n\n    accuracy                           0.78       352\n   macro avg       0.66      0.88      0.67       352\nweighted avg       0.93      0.78      0.82       352\n\nDifferent Samples from Test Set: \n\naccuracy3 0.72\nclassification report: \n               precision    recall  f1-score   support\n\n           0       1.00      0.70      0.82       147\n           1       0.19      1.00      0.31        10\n\n    accuracy                           0.72       157\n   macro avg       0.59      0.85      0.57       157\nweighted avg       0.95      0.72      0.79       157\n\n"
     ]
    }
   ],
   "source": [
    "svm.fit(df_2[X], df_2[y])\n",
    "test3 = svm.predict(df_test[X])\n",
    "accuracy3 = accuracy_score(df_test['fail_in_1h'], test3 )\n",
    "cls3 = classification_report(df_test['fail_in_1h'], test3)\n",
    "print(\"Full Test Set: \\n\")\n",
    "print(\"accuracy3\", round(accuracy3,3))\n",
    "print(\"classification report: \\n\", cls3)\n",
    "\n",
    "test3 = svm.predict(df_1[X])\n",
    "accuracy3 = accuracy_score(df_1['fail_in_1h'], test3 )\n",
    "cls3 = classification_report(df_1['fail_in_1h'], test3)\n",
    "print(\"Same Samples from Test Set: \\n\")\n",
    "print(\"accuracy3\", round(accuracy3,3))\n",
    "print(\"classification report: \\n\", cls3)\n",
    "\n",
    "test3 = svm.predict(df_test2[X])\n",
    "accuracy3 = accuracy_score(df_test2['fail_in_1h'], test3 )\n",
    "cls3 = classification_report(df_test2['fail_in_1h'], test3)\n",
    "print(\"Different Samples from Test Set: \\n\")\n",
    "print(\"accuracy3\", round(accuracy3,3))\n",
    "print(\"classification report: \\n\", cls3)"
   ]
  }
 ]
}