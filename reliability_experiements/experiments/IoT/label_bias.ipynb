{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Predictive Maintenance - Label Bias"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT LIBRARIES\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer, MinMaxScaler, normalize\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "### READ DATA\n",
    "##### Needs to be ran from the project directory\n",
    "train_measurements = pd.read_csv('../../datasets/IoT/measurements.csv')\n",
    "train_measurements = train_measurements.sort_values(by=['measurement_time'], ascending=[True])\n",
    "\n",
    "train_failures = pd.read_csv('../../datasets/IoT/failures.csv')\n",
    "train_failures = train_failures.sort_values(by=['failure_time'], ascending=[True])"
   ]
  },
  {
   "source": [
    "## Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_measurements.measurement_time = pd.to_datetime(train_measurements.measurement_time, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "train_failures.failure_time = pd.to_datetime(train_failures.failure_time)\n",
    "\n",
    "### MERGE NEXT FAILURE TO MEASUREMENTS\n",
    "train_combined = pd.merge_asof(\n",
    "    train_measurements,\n",
    "    train_failures,\n",
    "    left_on='measurement_time',\n",
    "    right_on='failure_time',\n",
    "    by='gadget_id',\n",
    "    direction='forward',\n",
    ")\n",
    "\n",
    "### TRANSFORM COLUMNS\n",
    "train_combined['time_to_fail'] = train_combined['failure_time']-train_combined['measurement_time']\n",
    "train_combined['fail_in_1h'] = np.where(train_combined['time_to_fail']<pd.Timedelta(hours=1), 1, 0)\n",
    "\n",
    "### CALCULATE RUNNING MEASURES\n",
    "train_combined = train_combined.reset_index(drop=True)\n",
    "train_combined = train_combined.sort_values(by=['gadget_id', 'measurement_time'], ascending=[True, True])\n",
    "\n",
    "train_combined['temperature_6h_std'] = train_combined.groupby('gadget_id')['temperature'].rolling(6).std(ddof=0).reset_index(drop=True)\n",
    "train_combined['pressure_6h_mean'] = train_combined.groupby('gadget_id')['pressure'].rolling(6).mean().reset_index(drop=True)\n",
    "\n",
    "train_combined.to_csv('../../datasets/IoT/train_combined.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      3.453742\n",
       "1      3.803752\n",
       "2      3.679122\n",
       "3      9.337838\n",
       "4      3.253625\n",
       "         ...   \n",
       "973    2.523321\n",
       "974    4.888758\n",
       "975    3.862833\n",
       "976    5.541126\n",
       "977    4.835146\n",
       "Name: temperature_6h_std, Length: 978, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# specify labels\n",
    "X = ['vibration_y', 'pressure_6h_mean', 'temperature_6h_std']\n",
    "y = 'fail_in_1h'\n",
    "cols = X + [y]\n",
    "\n",
    "df_to_split = train_combined.copy()\n",
    "df_to_split = df_to_split.dropna(subset=cols)\n",
    "df_to_split = df_to_split.reset_index(drop=True)\n",
    "\n",
    "##### Create binary bins to \n",
    "binner = KBinsDiscretizer(n_bins=10, encode='onehot-dense', strategy='kmeans')\n",
    "binner.fit(df_to_split[X])\n",
    "arr_bins= binner.transform(df_to_split[X])\n",
    "df_bins = pd.DataFrame(arr_bins)\n",
    "\n",
    "X = list(df_bins.columns)\n",
    "cols = X + [y]\n",
    "\n",
    "df_to_split = pd.concat([df_to_split, df_bins], axis=1)\n",
    "df_to_split['temperature_6h_std']"
   ]
  },
  {
   "source": [
    "### Split balanced dataset randomly into Train and Validation "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(651, 43)\n(327, 43)\n"
     ]
    }
   ],
   "source": [
    "# create test set (environmental dataset)\n",
    "df_test = df_to_split[df_to_split['gadget_id'].isin([5,6])].reset_index(drop=True)\n",
    "\n",
    "# create training, validation set\n",
    "df_to_split = df_to_split[df_to_split['gadget_id'].isin([1,2,3,4])].reset_index(drop=True)\n",
    "\n",
    "print(df_to_split.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Balanced\n--------------\nTraining dataset samples:  (456, 43)\nValidation dataset samples:  (195, 43)\n"
     ]
    }
   ],
   "source": [
    "# Use 70% of remaining data set for training\n",
    "df_train = df_to_split.sample(frac = 0.7).copy()\n",
    "\n",
    "# Remaining 30% used for validation test\n",
    "df_validation = df_to_split.drop(df_train.index).copy()\n",
    "\n",
    "\n",
    "df_train = df_train.sort_values(by=['gadget_id', 'measurement_time'], ascending=[True, True])\n",
    "df_validation = df_validation.sort_values(by=['gadget_id', 'measurement_time'], ascending=[True, True])\n",
    "\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_validation = df_validation.reset_index(drop=True)\n",
    "\n",
    "print(\"Balanced\")\n",
    "print(\"--------------\")\n",
    "print(\"Training dataset samples: \", df_train.shape)\n",
    "print(\"Validation dataset samples: \",df_validation.shape)"
   ]
  },
  {
   "source": [
    "### Split unbalanced dataset randomly into Train and Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csv to manually unbalance data\n",
    "df_random = df_to_split.sample(frac=1).reset_index(drop=True).copy()\n",
    "\n",
    "length=32\n",
    "start=32\n",
    "for i in range(length):\n",
    "    df_random.at[i, 'fail_in_1h']=110\n",
    "\n",
    "for i in range(start, start+length):\n",
    "    df_random.at[i, 'temperature_6h_std']=110\n",
    "\n",
    "\n",
    "df_unbalanced_to_split = df_random.sort_values(by=['measurement_time'], ascending=[True])\n",
    "\n",
    "# df_unbalanced_to_split.measurement_time = pd.to_datetime(df_unbalanced_to_split.measurement_time, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "# df_unbalanced_to_split.failure_time = pd.to_datetime(df_unbalanced_to_split.failure_time)\n",
    "\n",
    "df_unbalanced_to_split = df_unbalanced_to_split.reset_index(drop=True)\n",
    "df_unbalanced_to_split = df_unbalanced_to_split.sort_values(by=['gadget_id', 'measurement_time'], ascending=[True, True])\n",
    "\n",
    "df_unbalanced_to_split.to_csv('../datasets/train_combined_unbalanced.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unbalanced\n--------------\nTraining dataset samples:  (456, 43)\nValidation dataset samples:  (195, 43)\n"
     ]
    }
   ],
   "source": [
    "# Use 70% of remaining data set for training\n",
    "df_train_unbalanced = df_unbalanced_to_split.sample(frac = 0.7)\n",
    "\n",
    "# Remaining 30% used for validation test\n",
    "df_validation_unbalanced = df_unbalanced_to_split.drop(df_train.index)\n",
    "\n",
    "\n",
    "df_train_unbalanced = df_train_unbalanced.sort_values(by=['gadget_id', 'measurement_time'], ascending=[True, True])\n",
    "df_validation_unbalanced = df_validation_unbalanced.sort_values(by=['gadget_id', 'measurement_time'], ascending=[True, True])\n",
    "\n",
    "\n",
    "df_train_unbalanced = df_train_unbalanced.reset_index(drop=True)\n",
    "df_validation_unbalanced = df_validation_unbalanced.reset_index(drop=True)\n",
    "\n",
    "print(\"Unbalanced\")\n",
    "print(\"--------------\")\n",
    "print(\"Training dataset samples: \", df_train_unbalanced.shape)\n",
    "print(\"Validation dataset samples: \",df_validation_unbalanced.shape)"
   ]
  },
  {
   "source": [
    "# Training, Validation and Test - SVM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Balanced"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "validation accuracy 0.713\ntest accuracy 0.786\n"
     ]
    }
   ],
   "source": [
    "### PREDICTION PARAMETERS\n",
    "w0 = 1\n",
    "w1 = 8\n",
    "pos_label = 1\n",
    "\n",
    "### SVM\n",
    "svm = SVC(\n",
    "    class_weight={0:w0, 1:w1},\n",
    "    C=1,\n",
    "    random_state=42,\n",
    "    kernel='linear'\n",
    ")\n",
    "\n",
    "# fit model\n",
    "svm.fit(df_train[X], df_train[y])\n",
    "\n",
    "# make prediction on validation set\n",
    "val_pred = svm.predict(df_validation[X])\n",
    "\n",
    "accuracy_val = accuracy_score(df_validation['fail_in_1h'], val_pred )\n",
    "print(\"validation accuracy\", round(accuracy_val,3))\n",
    "\n",
    "# make prediction on test set\n",
    "test_pred = svm.predict(df_test[X])\n",
    "\n",
    "accuracy_test = accuracy_score(df_test['fail_in_1h'], test_pred )\n",
    "print(\"test accuracy\", round(accuracy_test, 3))"
   ]
  },
  {
   "source": [
    "## Unbalanced"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "validation accuracy 0.744\ntest accuracy 0.792\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "svm.fit(df_train_unbalanced[X], df_train_unbalanced[y])\n",
    "\n",
    "# make prediction on validation set\n",
    "val_pred_unbalanced = svm.predict(df_validation_unbalanced[X])\n",
    "\n",
    "accuracy_val_unbalanced = accuracy_score(df_validation_unbalanced['fail_in_1h'],val_pred_unbalanced )\n",
    "print(\"validation accuracy\", round(accuracy_val_unbalanced,3))\n",
    "\n",
    "# make prediction on test set\n",
    "test_pred_unbalanced = svm.predict(df_test[X])\n",
    "\n",
    "accuracy_test_unbalanced = accuracy_score(df_test['fail_in_1h'], test_pred_unbalanced)\n",
    "print(\"test accuracy\", round(accuracy_test_unbalanced, 3))"
   ]
  },
  {
   "source": [
    "# Tests\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   First  Second  Third\n0      1       9      1\n1      2       8      2\n2      3       7      1\n3      4       6      2\n4      5       5      2\n5      6       4      0\n"
     ]
    }
   ],
   "source": [
    "data = {'First':  [1,2,3,4,5,6],\n",
    "        'Second': [9,8,7,6,5,4],\n",
    "        'Third': [1,2,1,2,2,0]}\n",
    "\n",
    "df = pd.DataFrame (data, columns = ['First','Second','Third'])\n",
    "\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   First  Second  Third\n0      1       9      1\n1     99       8      2\n2      3       7      1\n3     99       6      2\n4     99       5      2\n5     99       4      0\n"
     ]
    }
   ],
   "source": [
    "for i in df.index:\n",
    "    if df.at[i, 'Third'] == 0 or df.at[i, 'Third'] == 2:\n",
    "        df.at[i, 'First']=99\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length = 3\n",
    "# for i in range(length):\n",
    "#     df.at[i, 'Second']=7\n",
    "\n",
    "# print(df)"
   ]
  }
 ]
}