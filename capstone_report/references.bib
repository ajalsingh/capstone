
@article{chen,
  author  = {Q. {Chen} and W. {Wang} and F. {Wu} and S. {De} and R. {Wang} and B. {Zhang} and X. {Huang}},
  title   = {A Survey on an Emerging Area: Deep Learning for Smart City Data},
  journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},
  volume  = {3},
  year    = {2019},
  number  = {5},
  pages   = {4392-410},
  doi     = {10.1109/TETCI.2019.2907718}
}

@misc{Saif,
  author       = {I. {Saif} and B. {Ammanath}},
  title        = {‘Trustworthy AI’ Is A Framework To Help Manage Unique Risk.},
  howpublished = {MIT Technology Reviw},
  year         = {2020}
}

%3
@misc{Moutafis,
  author       = {Moutafis, R.},
  title        = {How Bad Facial Recognition Software Gets Black People Arrested.},
  howpublished = {towardsdatascience},
  year         = {2020}
}

%4
@inproceedings{9004327,
  author    = {B. {E} and L. R. {Flaih} and D. {Yuvaraj} and S. {K} and A. {Jayanthiladevi} and T. S. {Kumar}},
  booktitle = {2019 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)},
  title     = {Use Case of Artificial Intelligence in Machine Learning Manufacturing 4.0},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {656-659},
  doi       = {10.1109/ICCIKE47802.2019.9004327}
}

%5
@misc{saria2019tutorial,
  title         = {Tutorial: Safe and Reliable Machine Learning},
  author        = {Suchi Saria and Adarsh Subbaswamy},
  year          = {2019},
  howpublished  = {ACM Conference on Fairness, Accountability, and Transparency (FAT* 2019). },
  doi           = {1904.07204},
  archiveprefix = {arXiv}
}

%6
@misc{Amodei,
  title    = {Concrete Problems in AI Safety},
  author   = {Amodei,Dario and Olah,Chris and Steinhardt,Jacob and Christiano,Paul and Schulman,John and Mané,Dan},
  year     = {2016},
  month    = {Jul 25},
  journal  = {arXiv.org},
  language = {English},
  url      = {http://ezproxy.lib.uts.edu.au/login?url=https://www-proquest-com.ezproxy.lib.uts.edu.au/docview/2080231511?accountid=17095}
}

%7
@misc{Jiang,
  title   = {Identifying and Correcting Label Bias in Machine Learning},
  author  = {Jiang,Heinrich and Nachum,Ofir},
  year    = {2019},
  month   = {Jan 15},
  journal = {arXiv.org},
  url     = {http://ezproxy.lib.uts.edu.au/login?url=https://www-proquest-com.ezproxy.lib.uts.edu.au/docview/2167520030?accountid=17095}
}

%8
@article{Mohapatra,
  author  = {Mohapatra, Badri},
  year    = {2019},
  month   = {02},
  pages   = {1-6},
  title   = {Machine learning applications to smart city},
  volume  = {5},
  journal = {ACCENTS Transactions on Image Processing and Computer Vision},
  doi     = {10.19101/TIPCV.2018.412004}
}

%9
@misc{Jedamski,
  author       = {Jedamski, D. },
  title        = {Bias/Variance tradeoff - Applied Machine Learning: Foundations. LinkedIn Learning. },
  howpublished = {Available at \url{https://www.linkedin.com/learning/appliedmachine-learning-foundations/bias-variance-tradeoff?u=2129308}},
  year         = {2019}
}

%10
@inproceedings{inproceedings,
  author = {Luckey, Daniel and Fritz, Henrieke and Legatiuk, Dmitrii and Dragos, Kosmas and Smarsly, Kay},
  year   = {2020},
  month  = {08},
  pages  = {},
  title  = {Artificial intelligence techniques for smart city applications}
}

%11
@misc{Justsajid,
  author       = {Khan, S.},
  title        = {Understanding Machine Learning Methodology},
  howpublished = {Available at \url{http://justsajid.com/skills/datascience/understanding-machine-learningmethodology/ }},
  year         = {2020}
}

%12
@misc{deepsense,
  author       = {Migdal, P. },
  title        = {Keras or PyTorch as your first deep learning framework. },
  howpublished = {Available at \url{https://deepsense.ai/keras-or-pytorch/ }},
  year         = {2020}
}

%13
@misc{sires,
  author = {Sires, E.},
  title  = {9 Ways to Prevent Data Bias in Predictive Models.},
  year   = {2020}
}

%14
@misc{gupta,
  author       = {Gupta, R.},
  title        = {Machine Learning Security: 3 Risks To Be Aware Of. TechCentre. },
  howpublished = {Available at \url{https://www.plugandplaytechcenter.com/resources/machine-learning-security-3- risks-be-aware/ }},
  year         = {n.d.}
}

@book{Masashi,
  author         = {Joaquin Quiñonero-Candela, and Masashi Sugiyama},
  title          = {Dataset Shift in Machine Learning},
  publisher      = {MIT Press},
  year           = {2008}
}

@INPROCEEDINGS{RUL,
  author={V. {Mathew} and T. {Toby} and V. {Singh} and B. M. {Rao} and M. G. {Kumar}},
  booktitle={2017 IEEE International Conference on Circuits and Systems (ICCS)}, 
  title={Prediction of Remaining Useful Lifetime (RUL) of turbofan engine using machine learning}, 
  year={2017},
  volume={},
  number={},
  pages={306-311},
  doi={10.1109/ICCS1.2017.8326010}}

  @article{amiri_mehrpouyan_fridman_mallik_nallanathan_matolak_2018, 
  title={A Machine Learning Approach for Power Allocation in HetNets Considering QoS}, 
  DOI={10.1109/icc.2018.8422864}, 
  journal={2018 IEEE International Conference on Communications (ICC)}, 
  author={Amiri, Roohollah and Mehrpouyan, Hani and Fridman, Lex and Mallik, Ranjan K. and Nallanathan, Arumugam and Matolak, David}, 
  year={2018}}

  @INPROCEEDINGS{9221098,
  author={Hoong Ong, Kevin Shen and Niyato, Dusit and Yuen, Chau},
  booktitle={2020 IEEE 6th World Forum on Internet of Things (WF-IoT)}, 
  title={Predictive Maintenance for Edge-Based Sensor Networks: A Deep Reinforcement Learning Approach}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/WF-IoT48130.2020.9221098}}

  @article{JOO2020324,
title = {Traffic signal control for smart cities using reinforcement learning},
journal = {Computer Communications},
volume = {154},
pages = {324-330},
year = {2020},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2020.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0140366419312836},
author = {Hyunjin Joo and Syed Hassan Ahmed and Yujin Lim},
keywords = {Smart city, Q-learning, Traffic signal control, Traffic congestion},
abstract = {Traffic congestion is increasing globally, and this problem needs to be addressed by the traffic management system. Traffic signal control (TSC) is an effective method among various traffic management systems. In a dynamically changing and interconnected traffic environment, the currently model-based TSCs are not adaptive. In addition, with the rise of smart cities and IoT, there is a need for efficient TSCs that can handle large and complex data. To address this issue, this study proposes a TSC system to maximize the number of vehicles crossing an intersection and balances the signals between roads by using Q-learning (QL). The proposed system has a flexible structure that can be modified to suit the changes in the original structure of the intersection.}
}

@article{DBLP:journals/corr/abs-1908-04734,
  author    = {Tom Everitt and
               Marcus Hutter},
  title     = {Reward Tampering Problems and Solutions in Reinforcement Learning:
               {A} Causal Influence Diagram Perspective},
  journal   = {CoRR},
  volume    = {abs/1908.04734},
  year      = {2019},
  url       = {http://arxiv.org/abs/1908.04734},
  archivePrefix = {arXiv},
  eprint    = {1908.04734},
  timestamp = {Mon, 19 Aug 2019 13:21:03 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1908-04734.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{EverittFDH16,
  author    = {Tom Everitt and
               Daniel Filan and
               Mayank Daswani and
               Marcus Hutter},
  title     = {Self-Modification of Policy and Utility Function in Rational Agents},
  journal   = {CoRR},
  volume    = {abs/1605.03142},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.03142},
  archivePrefix = {arXiv},
  eprint    = {1605.03142},
  timestamp = {Mon, 13 Aug 2018 16:47:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/EverittFDH16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{multi-step,
author={Yuan,Yinlong and Zhu,Liang Y. and Gu,Zhenghui and Deng,Xiaoyan and Li,Yuanqing},
year={2019},
month={08},
title={A novel multi-step reinforcement learning method for solving 0RW1S34RfeSDcfkexd09rT2reward hacking1RW1S34RfeSDcfkexd09rT2},
journal={Applied Intelligence},
volume={49},
number={8},
pages={2874-2888},
note={Copyright - Applied Intelligence is a copyright of Springer, (2019). All Rights Reserved; Last updated - 2019-12-11},
abstract={Reinforcement learning with appropriately designed reward signal could be used to solve many sequential learning problems. However, in practice, the reinforcement learning algorithms could be broken in unexpected, counterintuitive ways. One of the failure modes is reward hacking which usually happens when a reward function makes the agent obtain high return in an unexpected way. This unexpected way may subvert the designer’s intentions and lead to accidents during training. In this paper, a new multi-step state-action value algorithm is proposed to solve the problem of reward hacking. Unlike traditional algorithms, the proposed method uses a new return function, which alters the discount of future rewards and no longer stresses the immediate reward as the main influence when selecting the current state action. The performance of the proposed method is evaluated on two games, Mappy and Mountain Car. The empirical results demonstrate that the proposed method can alleviate the negative impact of reward hacking and greatly improve the performance of reinforcement learning algorithm. Moreover, the results illustrate that the proposed method could also be applied to the continuous state space problem successfully.},
keywords={Computers--Computer Networks; Reinforcement learning; Robotics; Reward hacking; Multi-step methods; Algorithms; Performance enhancement; Machine learning; Failure modes; Markov analysis},
isbn={0924669X},
language={English},
url={http://ezproxy.lib.uts.edu.au/login?url=https://www-proquest-com.ezproxy.lib.uts.edu.au/scholarly-journals/novel-multi-step-reinforcement-learning-method/docview/2177848165/se-2?accountid=17095},
}

@article{Wireheading,
  author    = {Tom Everitt and
               Marcus Hutter},
  title     = {Avoiding Wireheading with Value Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1605.03143},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.03143},
  archivePrefix = {arXiv},
  eprint    = {1605.03143},
  timestamp = {Mon, 13 Aug 2018 16:47:53 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/EverittH16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}